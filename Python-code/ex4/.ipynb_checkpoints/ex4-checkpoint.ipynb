{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.optimize as opt\n",
    "import multiprocessing as mp\n",
    "import pandas as pd\n",
    "import scipy.io as sio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and Visualizing Data ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_layer_size  = 400\n",
    "hidden_layer_size = 25\n",
    "num_labels = 10\n",
    "print('Loading and Visualizing Data ...\\n')\n",
    "mat_contents = sio.loadmat('ex4data1.mat')\n",
    "X = mat_contents['X']\n",
    "y = mat_contents['y']\n",
    "m = len(y)\n",
    "#print(m)\n",
    "\n",
    "rand_indices = np.random.permutation(m)\n",
    "#print(rand_indices)\n",
    "rand_indices = rand_indices.reshape(-1, 1)\n",
    "sel = X[rand_indices[0:100, :]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arrangeParams(t1, t2):\n",
    "    #print(t1.shape)\n",
    "    #print(t2.shape)\n",
    "    return np.concatenate((t1.reshape(t1.size, 1, order='F'),\n",
    "                           t2.reshape(t2.size, 1, order='F'))\n",
    "                          , axis=0).flatten()\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def displayData(X):\n",
    "    fig, ax = plt.subplots(10,10,sharex=True,sharey=True)\n",
    "    img_num = 0\n",
    "    for i in range(10):\n",
    "        for j in range(10):\n",
    "            # Convert column vector into 20x20 pixel matrix\n",
    "            # You have to transpose to display correctly\n",
    "            img = X[img_num,:].reshape(20,20).T\n",
    "            ax[i][j].imshow(img,cmap='gray')\n",
    "            img_num += 1\n",
    "\n",
    "    return (fig, ax)\n",
    "    \n",
    "#figure, ax = displayData(sel)\n",
    "#figure.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading Saved Neural Network Parameters ...\n",
      "\n",
      "(25, 401)\n",
      "(10, 26)\n"
     ]
    }
   ],
   "source": [
    "print('\\nLoading Saved Neural Network Parameters ...\\n')\n",
    "nn_contents = sio.loadmat('ex4weights.mat')\n",
    "\n",
    "Theta1 = nn_contents['Theta1'] \n",
    "Theta2 = nn_contents['Theta2']\n",
    "print(Theta1.shape)\n",
    "print(Theta2.shape)\n",
    "\n",
    "nn_params = arrangeParams(Theta1, Theta2)\n",
    "#print(Theta1[0][1])\n",
    "#print(Theta2[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoidGradient(z):\n",
    "    return sigmoid(z) * (1-sigmoid(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nnCostFunctionPrateek(nn_params, input_layer_size, hidden_layer_size, num_labels, X, y, lamb):\n",
    "    m = X.shape[0]\n",
    "\n",
    "    X = np.c_[np.ones(m),X]\n",
    "    J=0\n",
    "    Theta1 = nn_params[:(hidden_layer_size*(input_layer_size+1))].reshape((input_layer_size+1),hidden_layer_size).T\n",
    "    Theta2 = nn_params[-(num_labels*(hidden_layer_size+1)):].reshape(num_labels,(hidden_layer_size+1))\n",
    "#     print(\"Theta1 shape \", Theta1.shape)\n",
    "#     print(\"Theta2 shape \", Theta2.shape)\n",
    "#     print(\"X shape \", X.shape)\n",
    "    a1 = sigmoid(X.dot(Theta1.T)) # X = 5000* 401 , Theta1.T =401*25 a1= 5000*25\n",
    "    assert(a1.shape==(X.shape[0],Theta1.shape[0]))\n",
    "    a1 = np.c_[np.ones(m), a1] # add ones in a1 so a1.shape = 5000*26\n",
    "    h= sigmoid(a1.dot(Theta2.T)) # a1=5000*26 and Theta2 =10*26 so h = 5000*10\n",
    "    assert(h.shape == (a1.shape[0],Theta2.shape[0]))\n",
    "    for i in range(1,num_labels+1):\n",
    "        yk = (y==i)*1\n",
    "        \n",
    "        h_of_x = (h[:,i-1].reshape(-1,1))\n",
    "        J = J - (np.sum((yk*np.log(h_of_x)) + ((1-yk)*np.log(1-h_of_x))))/m\n",
    "    \n",
    "    \n",
    "    rtheta1=np.sum(np.square(Theta1[:,1:]))\n",
    "    rtheta2=np.sum(np.square(Theta2[:,1:]))\n",
    "    bias = lamb/(2*m)\n",
    "    J= J+(bias*(rtheta1+rtheta2));\n",
    "    Del1=0\n",
    "    Del2=0\n",
    "    for t in range(1,m+1):\n",
    "        A1 = X[t-1:t].T\n",
    "        Z2 = Theta1.dot(A1)\n",
    "        a = np.array([1]).reshape(-1,1)\n",
    "        A2 = np.concatenate((a,sigmoid(Z2)), axis=0)\n",
    "        Z3 = Theta2.dot(A2)\n",
    "        H = sigmoid(Z3)\n",
    "        actual = y[t-1];\n",
    "        yk= np.zeros((num_labels,1))\n",
    "        yk[actual-1] = 1;\n",
    "        del3 = H - yk;\n",
    "        del2 =(Theta2[:,1:].T.dot(del3)) * sigmoidGradient(Z2)\n",
    "        Del1 = Del1 + del2 * A1.T\n",
    "        Del2 = Del2 + del3 * A2.T\n",
    "\n",
    "    Theta1_grad = (Del1/m) + (lamb/m) * np.concatenate((np.zeros((hidden_layer_size,1)),Theta1[:,1:]), axis=1)\n",
    "    Theta2_grad = (Del2/m) + (lamb/m) *  np.concatenate((np.zeros((num_labels,1)), Theta2[:,1:]), axis=1)\n",
    "\n",
    "    grad = np.concatenate((Theta1_grad.T.reshape(Theta1_grad.size,1), Theta2_grad.reshape(Theta2_grad.size,1)), axis=0)  \n",
    "    grad = grad.reshape(-1)\n",
    "    print(J, grad.shape)\n",
    "    return J,grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2876291651613189 (10285, 1)\n",
      "['Cost at parameters (loaded from ex4weights): \\n(this value should be about 0.287629)\\n'] 0.2876291651613189\n"
     ]
    }
   ],
   "source": [
    "def nnCostFunction(nn_params_l, input_layer_size_l, hidden_layer_size_l, num_labels_l, X_l, y_l, lambda_l):\n",
    "   \n",
    "    Theta1_l = nn_params_l[0:(hidden_layer_size_l * (input_layer_size_l + 1))].reshape(input_layer_size_l + 1, hidden_layer_size_l).T\n",
    "    Theta2_l = nn_params_l[(Theta1_l.size):nn_params_l.size].reshape(hidden_layer_size_l + 1, num_labels_l).T\n",
    "   \n",
    "    m = X_l.shape[0] #5000X400    \n",
    "    X_l = np.c_[np.ones((m, 1)), X_l] #5000X401\n",
    "   \n",
    "    z1 = X_l.dot(Theta1_l.T)\n",
    "    a1 = sigmoid(z1)\n",
    "    a1 = np.c_[np.ones((m, 1)), a1]\n",
    "    \n",
    "    z2=  a1.dot(Theta2_l.T)\n",
    "    h = sigmoid(z2)\n",
    "   \n",
    "    J = 0\n",
    "    for k in range(1, num_labels_l + 1):\n",
    "        yk = (y_l==k) * 1\n",
    "        J = J - (1/m) * np.sum(yk * np.log(h.T[k-1:k].T) + (1-yk) * np.log(1-h.T[k-1:k].T))    \n",
    "  \n",
    "    \n",
    "    rtheta1 = np.sum(np.square(Theta1_l[:,1:]))\n",
    "    rtheta2 = np.sum(np.square(Theta2_l[:,1:]))\n",
    "    bias = lambda_l/(2*m)\n",
    "    \n",
    "    J= J + (bias * (rtheta1+rtheta2))\n",
    "    \n",
    "    Del1, Del2 = 0, 0\n",
    "    \n",
    "    for t in range(m): \n",
    "        A1 = X_l[t,:].T.reshape(-1, 1) # all columns with one row at a time\n",
    "        Z2 = Theta1_l.dot(A1)\n",
    "        A2 = np.concatenate((np.c_[np.array([1])], sigmoid(Z2).reshape(-1,1)))\n",
    "        Z3 = Theta2_l.dot(A2)\n",
    "        H = sigmoid(Z3)\n",
    "        actual = y_l[t].reshape(-1,1)\n",
    "        yk = np.zeros((num_labels_l,1))\n",
    "        yk[actual - 1] = 1\n",
    "        del3 = H - yk;\n",
    "        del2 = (Theta2_l[:,1:].T.dot(del3)) * sigmoidGradient(Z2).reshape(-1, 1)\n",
    "       \n",
    "        Del1 = Del1 + del2 * A1.T\n",
    "        Del2 = Del2 + del3 * A2.T\n",
    "    \n",
    "       \n",
    "    Theta1_grad = (Del1/m) + (lambda_l/m) * np.c_[np.zeros((hidden_layer_size_l,1)), Theta1_l[:,1:]]\n",
    "    Theta2_grad = (Del2/m) + (lambda_l/m) * np.c_[np.zeros((num_labels_l,1)), Theta2_l[:,1:]]\n",
    "    \n",
    "    grad = arrangeParams(Theta1_grad, Theta2_grad)\n",
    "    grad = grad.reshape(-1, 1)\n",
    "    print(J, grad.shape)\n",
    "    return J, grad\n",
    "    \n",
    "#calling    \n",
    "lambda_val = 0\n",
    "\n",
    "J, grad = nnCostFunction(nn_params, input_layer_size, hidden_layer_size, num_labels, X, y, lambda_val)\n",
    "print(['Cost at parameters (loaded from ex4weights): \\n(this value should be about 0.287629)\\n'], J);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking Cost Function (w/ Regularization) ... \n",
      "\n",
      "0.38376985909092365 (10285, 1)\n",
      "['Cost at parameters (loaded from ex4weights):\\n(this value should be about 0.383770)\\n'] 0.38376985909092365\n"
     ]
    }
   ],
   "source": [
    "print('\\nChecking Cost Function (w/ Regularization) ... \\n')\n",
    "lambda_val = 1\n",
    "\n",
    "J, grad = nnCostFunction(nn_params, input_layer_size, hidden_layer_size, num_labels, X, y, lambda_val)\n",
    "print(['Cost at parameters (loaded from ex4weights):\\n(this value should be about 0.383770)\\n'], J)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating sigmoid gradient...\n",
      "\n",
      "Sigmoid gradient evaluated at [-1 -0.5 0 0.5 1]:\n",
      "  \n",
      "[0.19661193 0.23500371 0.25       0.23500371 0.19661193]\n"
     ]
    }
   ],
   "source": [
    "print('\\nEvaluating sigmoid gradient...\\n')\n",
    "\n",
    "g = sigmoidGradient(np.array([-1, -0.5, 0, 0.5, 1]))\n",
    "print('Sigmoid gradient evaluated at [-1 -0.5 0 0.5 1]:\\n  ')\n",
    "print(g)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randInitializeWeights(L_in, L_out):\n",
    "    epsilon_init = 0.12\n",
    "    return np.random.rand(L_out, 1 + L_in) * 2 * epsilon_init - epsilon_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initializing Neural Network Parameters ...\n",
      "\n",
      "[ 0.10302994 -0.0220073   0.08647456  0.11775641]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# ================ Part 6: Initializing Pameters ================\n",
    "#  In this part of the exercise, you will be starting to implment a two\n",
    "#  layer neural network that classifies digits. You will start by\n",
    "#  implementing a function to initialize the weights of the neural network\n",
    "#  (randInitializeWeights.m)\n",
    "np.random.seed(0) #always used before random for testing\n",
    "print('\\nInitializing Neural Network Parameters ...\\n')\n",
    "initial_Theta1 = randInitializeWeights(input_layer_size, hidden_layer_size)\n",
    "initial_Theta2 = randInitializeWeights(hidden_layer_size, num_labels)\n",
    "initial_nn_params = arrangeParams(initial_Theta1, initial_Theta2)\n",
    "print(initial_nn_params[1:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def debugInitializeWeights(fan_out, fan_in):\n",
    "    W = np.zeros((fan_out, 1 + fan_in))\n",
    "    W = (np.sin(np.arange(1, W.size + 1)).reshape(W.shape)) / 10\n",
    "    return W\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeNumericalGradient(J, theta):\n",
    "\n",
    "    numgrad = np.zeros(theta.shape)\n",
    "    perturb = np.zeros(theta.shape)\n",
    "    e = 1e-4\n",
    "    #print(\"---------computeNumericalGradient-----------------\")\n",
    "    #print(theta.size)\n",
    "    #print(\"---------computeNumericalGradient-----------------\")\n",
    "    for p in range(theta.size):\n",
    "        #Set perturbation vector\n",
    "        perturb[p] = e\n",
    "        loss1 = J(theta - perturb)\n",
    "        loss2 = J(theta + perturb)\n",
    "        #Compute Numerical Gradient\n",
    "        numgrad[p] = (loss2 - loss1) / (2*e)\n",
    "        perturb[p] = 0\n",
    "    return numgrad\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0001"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#np.exp(0.00001)\n",
    "1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkNNGradients(lamb=0):\n",
    "    input_layer_size = 3\n",
    "    hidden_layer_size = 5\n",
    "    num_labels = 3\n",
    "    m = 5\n",
    "    Theta1 = debugInitializeWeights(hidden_layer_size, input_layer_size)\n",
    "    Theta2 = debugInitializeWeights(num_labels, hidden_layer_size)\n",
    "    X  = debugInitializeWeights(m, input_layer_size - 1)\n",
    "    y = np.mod([i for i in range(1,m+1) ], num_labels).reshape(-1,1)\n",
    "    nn_params = arrangeParams(Theta1, Theta2)# np.concatenate((Theta1.T.reshape(Theta1.size,1), Theta2.reshape(Theta2.size,1)))\n",
    "\n",
    "    #print(Theta1)\n",
    "    #print(Theta2)\n",
    "    cost, grad = nnCostFunction(nn_params,input_layer_size,hidden_layer_size, num_labels, X, y, lamb)\n",
    "    \n",
    "    def reduced_cost_func(p): \n",
    "        #print(\"--------------------------------------\")\n",
    "        #print(p)\n",
    "        #print(\"--------------------------------------\")\n",
    "        return nnCostFunction(p,input_layer_size,hidden_layer_size,num_labels,X,y,lamb)[0]\n",
    "     \n",
    "    numgrad = computeNumericalGradient(reduced_cost_func, nn_params)\n",
    "\n",
    "    #print(np.c_[numgrad, grad])\n",
    "\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0993852797173775 (38, 1)\n",
      "2.0993835131753165 (38, 1)\n",
      "2.0993870462561848 (38, 1)\n",
      "2.099384308840557 (38, 1)\n",
      "2.0993862505997076 (38, 1)\n",
      "2.099385997846823 (38, 1)\n",
      "2.0993845615905786 (38, 1)\n",
      "2.099387027996981 (38, 1)\n",
      "2.099383531446314 (38, 1)\n",
      "2.0993864489217042 (38, 1)\n",
      "2.099384110508848 (38, 1)\n",
      "2.0993852313567896 (38, 1)\n",
      "2.0993853280779513 (38, 1)\n",
      "2.099385256046543 (38, 1)\n",
      "2.0993853033882366 (38, 1)\n",
      "2.099385302578475 (38, 1)\n",
      "2.099385256856291 (38, 1)\n",
      "2.0993853280671604 (38, 1)\n",
      "2.0993852313676316 (38, 1)\n",
      "2.0993853090927916 (38, 1)\n",
      "2.0993852503419443 (38, 1)\n",
      "2.099385209040645 (38, 1)\n",
      "2.0993853503940785 (38, 1)\n",
      "2.0993852513520173 (38, 1)\n",
      "2.09938530808279 (38, 1)\n",
      "2.099385319871672 (38, 1)\n",
      "2.099385239563108 (38, 1)\n",
      "2.0993853514222853 (38, 1)\n",
      "2.0993852080125506 (38, 1)\n",
      "2.099385317046896 (38, 1)\n",
      "2.09938524238782 (38, 1)\n",
      "2.0993852517043696 (38, 1)\n",
      "2.0993853077303797 (38, 1)\n",
      "2.099385272736462 (38, 1)\n",
      "2.0993852866983027 (38, 1)\n",
      "2.099385300247191 (38, 1)\n",
      "2.099385259187569 (38, 1)\n",
      "2.0993853088522316 (38, 1)\n",
      "2.0993852505825394 (38, 1)\n",
      "2.099385290680421 (38, 1)\n",
      "2.0993852687543266 (38, 1)\n",
      "2.0993743461947165 (38, 1)\n",
      "2.0993962157391644 (38, 1)\n",
      "2.099374467666789 (38, 1)\n",
      "2.0993960942673047 (38, 1)\n",
      "2.0993346539299615 (38, 1)\n",
      "2.0994359080044003 (38, 1)\n",
      "2.099379600405003 (38, 1)\n",
      "2.099390959708704 (38, 1)\n",
      "2.0993796068608583 (38, 1)\n",
      "2.0993909532529056 (38, 1)\n",
      "2.099358892039411 (38, 1)\n",
      "2.0994116680744273 (38, 1)\n",
      "2.0993800270179857 (38, 1)\n",
      "2.099390532984108 (38, 1)\n",
      "2.0993801355717636 (38, 1)\n",
      "2.0993904244303785 (38, 1)\n",
      "2.099361158453472 (38, 1)\n",
      "2.0994094015487312 (38, 1)\n",
      "2.09937974461278 (38, 1)\n",
      "2.0993908154709224 (38, 1)\n",
      "2.099379797081032 (38, 1)\n",
      "2.0993907630027246 (38, 1)\n",
      "2.099359482331047 (38, 1)\n",
      "2.099411077752781 (38, 1)\n",
      "2.0993796871354107 (38, 1)\n",
      "2.099390872952079 (38, 1)\n",
      "2.0993797107784546 (38, 1)\n",
      "2.0993908493090903 (38, 1)\n",
      "2.09935940685161 (38, 1)\n",
      "2.099411153236005 (38, 1)\n",
      "2.0993800446536803 (38, 1)\n",
      "2.099390515347314 (38, 1)\n",
      "2.0993801620440085 (38, 1)\n",
      "2.099390397957033 (38, 1)\n",
      "2.0993611816218456 (38, 1)\n",
      "2.0994093783792573 (38, 1)\n",
      "[[ 1.76654043e-02  1.27220311e-02]\n",
      " [ 9.70879575e-03  6.46352265e-03]\n",
      " [-7.18128122e-03 -5.74199923e-03]\n",
      " [-1.74827533e-02 -1.26792390e-02]\n",
      " [-1.16920643e-02 -7.94573535e-03]\n",
      " [ 4.83605809e-04  1.58832809e-04]\n",
      " [ 2.36708468e-04  2.34983735e-05]\n",
      " [-2.28610919e-04 -1.34052019e-04]\n",
      " [-4.83497644e-04 -1.67913187e-04]\n",
      " [-2.93754236e-04 -4.76254501e-05]\n",
      " [ 7.06767167e-04  2.17690455e-04]\n",
      " [ 2.83653863e-04 -3.74199098e-05]\n",
      " [-4.01542821e-04 -2.59146269e-04]\n",
      " [-7.17048674e-04 -2.41809017e-04]\n",
      " [-3.73295381e-04 -2.64923844e-06]\n",
      " [ 2.80130050e-04  7.64045009e-05]\n",
      " [ 6.98092029e-05 -6.39345006e-05]\n",
      " [-2.05298110e-04 -1.45982634e-04]\n",
      " [-2.91348461e-04 -9.33867522e-05]\n",
      " [-1.09630471e-04  4.47626708e-05]\n",
      " [ 1.09347722e-01  1.09347722e-01]\n",
      " [ 1.08133003e-01  1.08133003e-01]\n",
      " [ 5.06270372e-01  3.06270372e-01]\n",
      " [ 5.67965185e-02  5.67965185e-02]\n",
      " [ 5.67319602e-02  5.67319602e-02]\n",
      " [ 2.63880175e-01  1.59463135e-01]\n",
      " [ 5.25298306e-02  5.25298306e-02]\n",
      " [ 5.14442931e-02  5.14442931e-02]\n",
      " [ 2.41215476e-01  1.45570264e-01]\n",
      " [ 5.53542907e-02  5.53542907e-02]\n",
      " [ 5.48296085e-02  5.48296085e-02]\n",
      " [ 2.57977109e-01  1.56700533e-01]\n",
      " [ 5.59290833e-02  5.59290833e-02]\n",
      " [ 5.56926532e-02  5.56926532e-02]\n",
      " [ 2.58731922e-01  1.56043968e-01]\n",
      " [ 5.23534682e-02  5.23534682e-02]\n",
      " [ 5.11795651e-02  5.11795651e-02]\n",
      " [ 2.40983787e-01  1.45771544e-01]]\n"
     ]
    }
   ],
   "source": [
    "# print('\\nChecking Backpropagation... \\n');\n",
    "\n",
    "# #Check gradients by running checkNNGradients\n",
    "checkNNGradients()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking Backpropagation (w/ Regularization) ... \n",
      "\n",
      "2.1459566783371105 (38, 1)\n",
      "2.1459549117950494 (38, 1)\n",
      "2.1459584448759177 (38, 1)\n",
      "2.1459557074602897 (38, 1)\n",
      "2.1459576492194405 (38, 1)\n",
      "2.1459573964665557 (38, 1)\n",
      "2.1459559602103115 (38, 1)\n",
      "2.1459584266167138 (38, 1)\n",
      "2.145954930066047 (38, 1)\n",
      "2.145957847541437 (38, 1)\n",
      "2.145955509128581 (38, 1)\n",
      "2.1459511771919613 (38, 1)\n",
      "2.145962185482245 (38, 1)\n",
      "2.145958334159265 (38, 1)\n",
      "2.14595502851498 (38, 1)\n",
      "2.145959968324873 (38, 1)\n",
      "2.1459533943493585 (38, 1)\n",
      "2.145950786042759 (38, 1)\n",
      "2.1459625766314985 (38, 1)\n",
      "2.145961216636005 (38, 1)\n",
      "2.1459521460381965 (38, 1)\n",
      "2.1459557639403295 (38, 1)\n",
      "2.1459575987338595 (38, 1)\n",
      "2.145952711052158 (38, 1)\n",
      "2.145960651622115 (38, 1)\n",
      "2.145962721432644 (38, 1)\n",
      "2.145950641241601 (38, 1)\n",
      "2.145952851314977 (38, 1)\n",
      "2.1459605113593243 (38, 1)\n",
      "2.1459558194033708 (38, 1)\n",
      "2.1459575432708107 (38, 1)\n",
      "2.1459611941390744 (38, 1)\n",
      "2.145952168535141 (38, 1)\n",
      "2.1459507382067153 (38, 1)\n",
      "2.1459626244675154 (38, 1)\n",
      "2.145959921304432 (38, 1)\n",
      "2.1459534413697936 (38, 1)\n",
      "2.1459584378918644 (38, 1)\n",
      "2.145954924782372 (38, 1)\n",
      "2.1459512146286492 (38, 1)\n",
      "2.1459621480455637 (38, 1)\n",
      "2.1459457448144494 (38, 1)\n",
      "2.1459676143588973 (38, 1)\n",
      "2.145945866286522 (38, 1)\n",
      "2.1459674928870376 (38, 1)\n",
      "2.1459060525496945 (38, 1)\n",
      "2.146007306624133 (38, 1)\n",
      "2.1459455462401746 (38, 1)\n",
      "2.145967817112998 (38, 1)\n",
      "2.1459450723311115 (38, 1)\n",
      "2.1459682910221183 (38, 1)\n",
      "2.1459243500150094 (38, 1)\n",
      "2.145989013338294 (38, 1)\n",
      "2.14595058191767 (38, 1)\n",
      "2.145962781323889 (38, 1)\n",
      "2.1459490644805848 (38, 1)\n",
      "2.145964298761023 (38, 1)\n",
      "2.145928658346164 (38, 1)\n",
      "2.145984704895505 (38, 1)\n",
      "2.145955687047485 (38, 1)\n",
      "2.1459576762756836 (38, 1)\n",
      "2.1459544628274303 (38, 1)\n",
      "2.145958900495792 (38, 1)\n",
      "2.1459326113706796 (38, 1)\n",
      "2.1459807519526137 (38, 1)\n",
      "2.1459568423007913 (38, 1)\n",
      "2.145956521026164 (38, 1)\n",
      "2.1459571123394268 (38, 1)\n",
      "2.1459562509875836 (38, 1)\n",
      "2.145936576856294 (38, 1)\n",
      "2.145976786470787 (38, 1)\n",
      "2.1459531227664024 (38, 1)\n",
      "2.145960240474057 (38, 1)\n",
      "2.1459547831012493 (38, 1)\n",
      "2.1459585801392578 (38, 1)\n",
      "2.145937089165059 (38, 1)\n",
      "2.1459762740755095 (38, 1)\n",
      "[[ 0.0176654   0.01272203]\n",
      " [ 0.0097088   0.00646352]\n",
      " [-0.00718128 -0.005742  ]\n",
      " [-0.01748275 -0.01267924]\n",
      " [-0.01169206 -0.00794574]\n",
      " [ 0.05504145  0.05471668]\n",
      " [-0.01652822 -0.01674143]\n",
      " [-0.03286988 -0.03277532]\n",
      " [ 0.05895294  0.05926853]\n",
      " [-0.04535299 -0.04510686]\n",
      " [ 0.00917397  0.00868489]\n",
      " [ 0.03970285  0.03938178]\n",
      " [-0.06040096 -0.06025856]\n",
      " [ 0.03830022  0.03877546]\n",
      " [ 0.00861934  0.00898998]\n",
      " [-0.04512802 -0.04533175]\n",
      " [ 0.0594313   0.05929756]\n",
      " [-0.03239967 -0.03234036]\n",
      " [-0.01756555 -0.01736759]\n",
      " [ 0.05466708  0.05482148]\n",
      " [ 0.10934772  0.10934772]\n",
      " [ 0.108133    0.108133  ]\n",
      " [ 0.50627037  0.30627037]\n",
      " [ 0.11135436  0.11135436]\n",
      " [ 0.11609346  0.11609346]\n",
      " [ 0.32331662  0.21889958]\n",
      " [ 0.06099703  0.06099703]\n",
      " [ 0.0761714   0.0761714 ]\n",
      " [ 0.28023275  0.18458753]\n",
      " [ 0.00994614  0.00994614]\n",
      " [ 0.02218834  0.02218834]\n",
      " [ 0.24070291  0.13942633]\n",
      " [-0.00160637 -0.00160637]\n",
      " [-0.00430676 -0.00430676]\n",
      " [ 0.20104807  0.09836012]\n",
      " [ 0.03558854  0.03558854]\n",
      " [ 0.01898519  0.01898519]\n",
      " [ 0.19592455  0.10071231]]\n",
      "0.5760512469501331 (10285, 1)\n",
      "['\\n\\nCost at (fixed) debugging parameters (w/ lambda = %f): \\n(for lambda = 3, this value should be about 0.576051)\\n\\n'] 3 0.5760512469501331\n"
     ]
    }
   ],
   "source": [
    "print('\\nChecking Backpropagation (w/ Regularization) ... \\n')\n",
    "lambda_val = 3\n",
    "checkNNGradients(lambda_val)\n",
    "debug_J, debug_grad  = nnCostFunction(nn_params, input_layer_size, hidden_layer_size, num_labels, X, y, lambda_val);\n",
    "\n",
    "print(['\\n\\nCost at (fixed) debugging parameters (w/ lambda = %f): \\n(for lambda = 3, this value should be about 0.576051)\\n\\n'], lambda_val, debug_J)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Neural Network... \n",
      "\n",
      "6.909270510710377 (10285, 1)\n",
      "6.909270510710377 (10285, 1)\n",
      "4.351684303986592 (10285, 1)\n",
      "3.304453113873082 (10285, 1)\n",
      "3.254024171558584 (10285, 1)\n",
      "3.2463980418051968 (10285, 1)\n",
      "3.219764637381702 (10285, 1)\n",
      "3.173006291981995 (10285, 1)\n",
      "3.0332331460088486 (10285, 1)\n",
      "2.9170591525269134 (10285, 1)\n",
      "2.6866924547673654 (10285, 1)\n",
      "2.660525089713059 (10285, 1)\n",
      "2.2842999211248505 (10285, 1)\n",
      "2.297751842111555 (10285, 1)\n",
      "2.049531660488122 (10285, 1)\n",
      "1.930778251952054 (10285, 1)\n",
      "1.8532783110841131 (10285, 1)\n",
      "1.744318214121175 (10285, 1)\n",
      "1.6438132026145353 (10285, 1)\n",
      "1.5854617739813086 (10285, 1)\n",
      "1.542603031819505 (10285, 1)\n",
      "1.4857130217140375 (10285, 1)\n",
      "1.4425446239865014 (10285, 1)\n",
      "1.352208280327473 (10285, 1)\n",
      "1.3159236795453264 (10285, 1)\n",
      "1.2660018676285436 (10285, 1)\n",
      "1.2398195688821008 (10285, 1)\n",
      "1.2029863787560018 (10285, 1)\n",
      "1.174386533577021 (10285, 1)\n",
      "1.1109330536965558 (10285, 1)\n",
      "1.08785502426485 (10285, 1)\n",
      "1.050301434371719 (10285, 1)\n",
      "1.025239039466908 (10285, 1)\n",
      "0.9700129530369588 (10285, 1)\n",
      "0.9471501949728472 (10285, 1)\n",
      "0.9121190670347229 (10285, 1)\n",
      "0.9034036270317682 (10285, 1)\n",
      "0.8766684455879873 (10285, 1)\n",
      "0.8596622695967281 (10285, 1)\n",
      "0.839529942807324 (10285, 1)\n",
      "0.7998105416706125 (10285, 1)\n",
      "0.7873591511207383 (10285, 1)\n",
      "0.7612926607882661 (10285, 1)\n",
      "0.7559200173443711 (10285, 1)\n",
      "0.7420409291688712 (10285, 1)\n",
      "0.7381034823382681 (10285, 1)\n",
      "0.7260760591253175 (10285, 1)\n",
      "0.7192136984159702 (10285, 1)\n",
      "0.7122364685211485 (10285, 1)\n",
      "0.6964238342090348 (10285, 1)\n",
      "0.6889536088028422 (10285, 1)\n",
      "0.6741399365756376 (10285, 1)\n",
      "0.6702836091725041 (10285, 1)\n",
      "0.6617194395749414 (10285, 1)\n",
      "0.6588462850918091 (10285, 1)\n",
      "0.6501410269891237 (10285, 1)\n",
      "0.6455167458251806 (10285, 1)\n",
      "0.6402884761975575 (10285, 1)\n",
      "0.6316464702548565 (10285, 1)\n",
      "0.6278819808749252 (10285, 1)\n",
      "0.6176767650740767 (10285, 1)\n",
      "0.6145138347256391 (10285, 1)\n",
      "0.6074552459085076 (10285, 1)\n",
      "0.6053073393441484 (10285, 1)\n",
      "0.5989417568711246 (10285, 1)\n",
      "0.5961560087270403 (10285, 1)\n",
      "0.5941882202144828 (10285, 1)\n",
      "0.5907294579471742 (10285, 1)\n",
      "0.5887157089840307 (10285, 1)\n",
      "0.5820569338573883 (10285, 1)\n",
      "0.575416578335143 (10285, 1)\n",
      "0.5687564715358528 (10285, 1)\n",
      "0.5521130152526296 (10285, 1)\n",
      "0.5484457876942299 (10285, 1)\n",
      "0.5424386936446091 (10285, 1)\n",
      "0.5404805366324574 (10285, 1)\n",
      "0.5357136807036964 (10285, 1)\n",
      "0.5345822023252012 (10285, 1)\n",
      "0.5320150202497221 (10285, 1)\n",
      "0.5315290405772257 (10285, 1)\n",
      "0.530052510704662 (10285, 1)\n",
      "0.529234147617729 (10285, 1)\n",
      "0.5280244559695431 (10285, 1)\n",
      "0.5241114755593469 (10285, 1)\n",
      "0.5207511267361576 (10285, 1)\n",
      "0.517770080454099 (10285, 1)\n",
      "0.5112470466628694 (10285, 1)\n",
      "0.509428916879159 (10285, 1)\n",
      "0.5043112425662399 (10285, 1)\n",
      "0.5026666239005682 (10285, 1)\n",
      "0.4992872650272623 (10285, 1)\n",
      "0.4901970391865132 (10285, 1)\n",
      "0.4875959910705022 (10285, 1)\n",
      "0.48453045504310505 (10285, 1)\n",
      "0.4837630050249949 (10285, 1)\n",
      "0.48216079441275517 (10285, 1)\n",
      "0.48170873089596666 (10285, 1)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-c0be216cc925>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m#min_cost_func(initial_nn_params)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_cost_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_nn_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjac\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'CG'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'maxiter'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'eps'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.8\u001b[0m \u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/scipy/optimize/_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    477\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_minimize_powell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'cg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 479\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_minimize_cg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjac\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    480\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'bfgs'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_minimize_bfgs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjac\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m_minimize_cg\u001b[0;34m(fun, x0, args, jac, callback, gtol, norm, eps, maxiter, disp, return_all, **unknown_options)\u001b[0m\n\u001b[1;32m   1308\u001b[0m                      _line_search_wolfe12(f, myfprime, xk, pk, gfk, old_fval,\n\u001b[1;32m   1309\u001b[0m                                           \u001b[0mold_old_fval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mamin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mamax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1310\u001b[0;31m                                           extra_condition=descent_condition)\n\u001b[0m\u001b[1;32m   1311\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0m_LineSearchError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1312\u001b[0m             \u001b[0;31m# Line search failed to find a better solution.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m_line_search_wolfe12\u001b[0;34m(f, fprime, xk, pk, gfk, old_fval, old_old_fval, **kwargs)\u001b[0m\n\u001b[1;32m    781\u001b[0m     ret = line_search_wolfe1(f, fprime, xk, pk, gfk,\n\u001b[1;32m    782\u001b[0m                              \u001b[0mold_fval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_old_fval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 783\u001b[0;31m                              **kwargs)\n\u001b[0m\u001b[1;32m    784\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mextra_condition\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/scipy/optimize/linesearch.py\u001b[0m in \u001b[0;36mline_search_wolfe1\u001b[0;34m(f, fprime, xk, pk, gfk, old_fval, old_old_fval, args, c1, c2, amax, amin, xtol)\u001b[0m\n\u001b[1;32m     99\u001b[0m     stp, fval, old_fval = scalar_search_wolfe1(\n\u001b[1;32m    100\u001b[0m             \u001b[0mphi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mderphi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_fval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_old_fval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mderphi0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m             c1=c1, c2=c2, amax=amax, amin=amin, xtol=xtol)\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mstp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_fval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgval\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/scipy/optimize/linesearch.py\u001b[0m in \u001b[0;36mscalar_search_wolfe1\u001b[0;34m(phi, derphi, phi0, old_phi0, derphi0, c1, c2, amax, amin, xtol)\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34mb'FG'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m             \u001b[0malpha1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m             \u001b[0mphi1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mphi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m             \u001b[0mderphi1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mderphi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/scipy/optimize/linesearch.py\u001b[0m in \u001b[0;36mphi\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mphi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mfc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxk\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mderphi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36mfunction_wrapper\u001b[0;34m(*wrapper_args)\u001b[0m\n\u001b[1;32m    290\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mwrapper_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0mncalls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper_args\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mncalls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-c0be216cc925>\u001b[0m in \u001b[0;36mmin_cost_func\u001b[0;34m(p)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m#res = opt.minimize(nnCostFunction, initial_nn_params, args=(input_layer_size, hidden_layer_size, num_labels, X, y, lambda_val), jac=True, options={'maxiter':50})\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmin_cost_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnnCostFunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_layer_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_layer_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-a1d9238f5ffd>\u001b[0m in \u001b[0;36mnnCostFunction\u001b[0;34m(nn_params_l, input_layer_size_l, hidden_layer_size_l, num_labels_l, X_l, y_l, lambda_l)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mA1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_l\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# all columns with one row at a time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mZ2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTheta1_l\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0mA2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZ2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mZ3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTheta2_l\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "#=================== Part 8: Training NN ===================\n",
    "#  You have now implemented all the code necessary to train a neural \n",
    "#  network. To train your neural network, we will now use \"fmincg\", which\n",
    "#  is a function which works similarly to \"fminunc\". Recall that these\n",
    "#  advanced optimizers are able to train our cost functions efficiently as\n",
    "#  long as we provide them with the gradient computations.\n",
    "#\n",
    "print('\\nTraining Neural Network... \\n')\n",
    "lambda_val = 1\n",
    "#print(initial_nn_params.shape)\n",
    "#res = opt.minimize(nnCostFunction, initial_nn_params, args=(input_layer_size, hidden_layer_size, num_labels, X, y, lambda_val), jac=True, options={'maxiter':50})\n",
    "def min_cost_func(p):\n",
    "    j, g = nnCostFunction(p, input_layer_size, hidden_layer_size, num_labels, X, y, lambda_val)\n",
    "    return j, g.flatten()\n",
    "\n",
    "\n",
    "#min_cost_func(initial_nn_params)\n",
    "res = opt.minimize(min_cost_func, initial_nn_params, jac=True, method='CG', options={'maxiter':120, 'eps': 0.8 })\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test1(a, b, c):\n",
    "    print(\"in test1\")\n",
    "    print(\"a = \", a)\n",
    "    print(\"b = \", b)\n",
    "    print(\"c = \", c)\n",
    "\n",
    "def test2():\n",
    "    a1 = 10\n",
    "    b1 = 20\n",
    "    c1 = 30\n",
    "    def test3(d):\n",
    "        print(\"d = \", d)\n",
    "        return \"test3\"\n",
    "    test1(test3, b1, c1)\n",
    "\n",
    "test2()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(a[:,2:3])\n",
    "#a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.rand(4, 4)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A1 = a[1,:].T.reshape(-1, 1)\n",
    "A1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A2 = a[1:2].T\n",
    "A2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.random.rand(4, 1)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((y[2]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y[2,:].reshape(-1, 1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
