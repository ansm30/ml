{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.optimize as opt\n",
    "import multiprocessing as mp\n",
    "import pandas as pd\n",
    "import scipy.io as sio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and Visualizing Data ...\n",
      "\n",
      "5000\n",
      "[1645 3102 3293 ... 3535 2104 1476]\n"
     ]
    }
   ],
   "source": [
    "input_layer_size  = 400\n",
    "hidden_layer_size = 25\n",
    "num_labels = 10\n",
    "print('Loading and Visualizing Data ...\\n')\n",
    "mat_contents = sio.loadmat('ex4data1.mat')\n",
    "X = mat_contents['X']\n",
    "y = mat_contents['y']\n",
    "m = len(y)\n",
    "print(m)\n",
    "\n",
    "rand_indices = np.random.permutation(m)\n",
    "print(rand_indices)\n",
    "rand_indices = rand_indices.reshape(-1, 1)\n",
    "sel = X[rand_indices[0:100, :]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arrangeParams(t1, t2):\n",
    "    return np.concatenate((t1.reshape(t1.size, 1, order='F'), t2.reshape(t2.size, 1, order='F')), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "def displayData(X):\n",
    "    fig, ax = plt.subplots(10,10,sharex=True,sharey=True)\n",
    "    img_num = 0\n",
    "    for i in range(10):\n",
    "        for j in range(10):\n",
    "            # Convert column vector into 20x20 pixel matrix\n",
    "            # You have to transpose to display correctly\n",
    "            img = X[img_num,:].reshape(20,20).T\n",
    "            ax[i][j].imshow(img,cmap='gray')\n",
    "            img_num += 1\n",
    "\n",
    "    return (fig, ax)\n",
    "    \n",
    "#figure, ax = displayData(sel)\n",
    "#figure.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading Saved Neural Network Parameters ...\n",
      "\n",
      "(25, 401)\n",
      "(10, 26)\n",
      "-1.0562416310683364e-08\n",
      "-1.2124449845935756\n"
     ]
    }
   ],
   "source": [
    "print('\\nLoading Saved Neural Network Parameters ...\\n')\n",
    "nn_contents = sio.loadmat('ex4weights.mat')\n",
    "\n",
    "Theta1 = nn_contents['Theta1']\n",
    "Theta2 = nn_contents['Theta2']\n",
    "\n",
    "nn_params = arrangeParams(Theta1, Theta2)\n",
    "print(Theta1.shape)\n",
    "print(Theta2.shape)\n",
    "print(Theta1[0][1])\n",
    "print(Theta2[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoidGradient(z):\n",
    "    return sigmoid(z) * (1-sigmoid(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Cost at parameters (loaded from ex4weights): \\n(this value should be about 0.287629)\\n'] 0.2876291651613189\n"
     ]
    }
   ],
   "source": [
    "def nnCostFunction(nn_params_l, input_layer_size_l, hidden_layer_size_l, num_labels_l, X_l, y_l, lambda_l):\n",
    "    #print(input_layer_size_l)\n",
    "    #print(hidden_layer_size_l)\n",
    "    #Theta1 = reshape(nn_params_l(1:hidden_layer_size_l * (input_layer_size_l + 1)), hidden_layer_size_l, (input_layer_size_l + 1));\n",
    "    Theta1_l = nn_params_l[0:(hidden_layer_size_l * (input_layer_size_l + 1))].reshape(input_layer_size_l + 1, hidden_layer_size_l).T\n",
    "    Theta2_l = nn_params_l[(Theta1_l.size):nn_params_l.size].reshape(hidden_layer_size_l + 1, num_labels_l).T\n",
    "    #print(Theta1_l[0][1])\n",
    "    #print(Theta2_l[0][1])\n",
    "    #print('\\nFeedforward Using Neural Network ...\\n')\n",
    "    #print(X_l.shape[0])\n",
    "    m = X_l.shape[0] #5000X400    \n",
    "    X_l = np.c_[np.ones((m, 1)), X_l] #5000X401\n",
    "    z1 = X_l.dot(Theta1_l.T)\n",
    "    a1 = sigmoid(z1)\n",
    "    a1 = np.c_[np.ones((m, 1)), a1]\n",
    "    \n",
    "    z2=  a1.dot(Theta2_l.T)\n",
    "\n",
    "    h = sigmoid(z2)\n",
    "    #print(h[: 2])\n",
    "    J = 0\n",
    "    for k in range(1, num_labels_l + 1):\n",
    "        yk = (y_l==k) * 1\n",
    "        J = J - (1/m) * np.sum(yk * np.log(h.T[k-1:k].T) + (1-yk) * np.log(1-h.T[k-1:k].T))    \n",
    "    #print(J)\n",
    "    \n",
    "    rtheta1 = np.sum(np.sum(np.square(Theta1_l[:,1:])))\n",
    "    rtheta2 = np.sum(np.sum(np.square(Theta2_l[:,1:])))\n",
    "    bias = lambda_l/(2*m)\n",
    "    \n",
    "    J= J + (bias * (rtheta1+rtheta2))\n",
    "    Del1, Del2 = 0, 0\n",
    "    \n",
    "    for t in range(m): \n",
    "        A1 = X_l[t,:].T.reshape(-1, 1) # all columns with one row at a time\n",
    "        Z2 = Theta1_l.dot(A1)\n",
    "        A2 = np.concatenate((np.c_[np.array([1])], sigmoid(Z2).reshape(-1,1)))\n",
    "        Z3 = Theta2_l.dot(A2)\n",
    "        H = sigmoid(Z3)\n",
    "        actual = y_l[t,:].reshape(-1,1)\n",
    "        yk = np.zeros((num_labels_l,1))\n",
    "        yk[actual - 1] = 1\n",
    "        del3 = H - yk;\n",
    "        del2 = (Theta2_l[:,1:].T.dot(del3)) * sigmoidGradient(Z2).reshape(-1, 1)\n",
    "        #print(A2.shape)\n",
    "        Del1 = Del1 + del2.dot(A1.T)\n",
    "        Del2 = Del2 + del3.dot(A2.T)\n",
    "    \n",
    "    #print(np.sum(np.sum(Del2)))\n",
    "    \n",
    "    Theta1_grad = (Del1/m) + (lambda_l/m) * np.c_[np.zeros((hidden_layer_size_l,1)), Theta1_l[:,1:]]\n",
    "    Theta2_grad = (Del2/m) + (lambda_l/m) * np.c_[np.zeros((num_labels_l,1)), Theta2_l[:,1:]]\n",
    "    return J, arrangeParams(Theta1_grad, Theta2_grad)# np.concatenate((Theta1_grad.reshape(Theta1_grad.size, 1, order='F'), Theta2_grad.reshape(Theta2_grad.size, 1, order='F')), axis=0)\n",
    "    \n",
    "#calling    \n",
    "lambda_val = 0\n",
    "\n",
    "J, grad = nnCostFunction(nn_params, input_layer_size, hidden_layer_size, num_labels, X, y, lambda_val)\n",
    "print(['Cost at parameters (loaded from ex4weights): \\n(this value should be about 0.287629)\\n'], J);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking Cost Function (w/ Regularization) ... \n",
      "\n",
      "['Cost at parameters (loaded from ex4weights):\\n(this value should be about 0.383770)\\n'] 0.38376985909092365\n"
     ]
    }
   ],
   "source": [
    "print('\\nChecking Cost Function (w/ Regularization) ... \\n')\n",
    "lambda_val = 1\n",
    "\n",
    "J, grad = nnCostFunction(nn_params, input_layer_size, hidden_layer_size, num_labels, X, y, lambda_val)\n",
    "print(['Cost at parameters (loaded from ex4weights):\\n(this value should be about 0.383770)\\n'], J)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating sigmoid gradient...\n",
      "\n",
      "Sigmoid gradient evaluated at [-1 -0.5 0 0.5 1]:\n",
      "  \n",
      "[0.19661193 0.23500371 0.25       0.23500371 0.19661193]\n"
     ]
    }
   ],
   "source": [
    "print('\\nEvaluating sigmoid gradient...\\n')\n",
    "\n",
    "g = sigmoidGradient(np.array([-1, -0.5, 0, 0.5, 1]))\n",
    "print('Sigmoid gradient evaluated at [-1 -0.5 0 0.5 1]:\\n  ')\n",
    "print(g)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randInitializeWeights(L_in, L_out):\n",
    "    epsilon_init = 0.12\n",
    "    return np.random.rand(L_out, 1 + L_in) * 2 * epsilon_init - epsilon_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initializing Neural Network Parameters ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# ================ Part 6: Initializing Pameters ================\n",
    "#  In this part of the exercise, you will be starting to implment a two\n",
    "#  layer neural network that classifies digits. You will start by\n",
    "#  implementing a function to initialize the weights of the neural network\n",
    "#  (randInitializeWeights.m)\n",
    "\n",
    "print('\\nInitializing Neural Network Parameters ...\\n')\n",
    "initial_Theta1 = randInitializeWeights(input_layer_size, hidden_layer_size)\n",
    "initial_Theta2 = randInitializeWeights(hidden_layer_size, num_labels)\n",
    "initial_nn_params = arrangeParams(initial_Theta1, initial_Theta2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "def debugInitializeWeights(fan_out, fan_in):\n",
    "    W = np.zeros((fan_out, 1 + fan_in))\n",
    "    W = np.sin(np.arange(1, W.size + 1)).reshape(W.shape) / 10\n",
    "    return W\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeNumericalGradient(J, aa, theta):\n",
    "\n",
    "    numgrad = np.zeros(theta.shape)\n",
    "    perturb = np.zeros(theta.shape)\n",
    "    e = 0.0001#1e-4\n",
    "    for p in range(theta.size):\n",
    "        #Set perturbation vector\n",
    "        perturb[p] = e;\n",
    "        loss1 = J(theta - perturb)\n",
    "        loss2 = J(theta + perturb)\n",
    "        #Compute Numerical Gradient\n",
    "        numgrad[p] = (loss2 - loss1) / (2*e)\n",
    "        perturb[p] = 0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0001"
      ]
     },
     "execution_count": 467,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#np.exp(0.00001)\n",
    "1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkNNGradients(lamb=0):\n",
    "    input_layer_size = 3\n",
    "    hidden_layer_size = 5\n",
    "    num_labels = 3\n",
    "    m = 5\n",
    "    Theta1 = debugInitializeWeights(hidden_layer_size, input_layer_size)\n",
    "    Theta2 = debugInitializeWeights(num_labels, hidden_layer_size)\n",
    "    X  = debugInitializeWeights(m, input_layer_size - 1)\n",
    "    y = np.mod([i for i in range(1,m+1) ], num_labels).reshape(-1,1)\n",
    "    print(Theta1.shape)\n",
    "    nn_params = np.concatenate((Theta1.T.reshape(Theta1.size,1), Theta2.reshape(Theta2.size,1)))\n",
    "\n",
    "    \n",
    "    cost, grad = nnCostFunction(nn_params,input_layer_size,hidden_layer_size, num_labels, X, y, lamb)\n",
    "    \n",
    "    def reduced_cost_func(p):\n",
    "        #print(\"--------------------------------------\")\n",
    "        #print(p)\n",
    "        #print(\"--------------------------------------\")\n",
    "        return nnCostFunction(p,input_layer_size,hidden_layer_size,num_labels,X,y,lamb)[0]\n",
    "     \n",
    "    numgrad = computeNumericalGradient(reduced_cost_func, 1, nn_params)\n",
    "\n",
    "    #print(numgrad, grad)\n",
    "\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 4)\n"
     ]
    }
   ],
   "source": [
    "# print('\\nChecking Backpropagation... \\n');\n",
    "\n",
    "# #Check gradients by running checkNNGradients\n",
    "checkNNGradients()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking Backpropagation (w/ Regularization) ... \n",
      "\n",
      "(5, 4)\n",
      "['\\n\\nCost at (fixed) debugging parameters (w/ lambda = %f): \\n(for lambda = 3, this value should be about 0.576051)\\n\\n'] 3 (0.5760512469501331, array([[ 6.18712766e-05],\n",
      "       [ 9.38798109e-05],\n",
      "       [-1.92593606e-04],\n",
      "       ...,\n",
      "       [ 1.34904586e-05],\n",
      "       [ 7.79237711e-05],\n",
      "       [-2.31823790e-05]]))\n"
     ]
    }
   ],
   "source": [
    "print('\\nChecking Backpropagation (w/ Regularization) ... \\n')\n",
    "lambda_val = 3\n",
    "checkNNGradients(lambda_val)\n",
    "debug_J, debug_grad  = nnCostFunction(nn_params, input_layer_size, hidden_layer_size, num_labels, X, y, lambda_val);\n",
    "\n",
    "print(['\\n\\nCost at (fixed) debugging parameters (w/ lambda = %f): \\n(for lambda = 3, this value should be about 0.576051)\\n\\n'], lambda_val, debug_J)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.14887099, 0.29848163, 0.09591432, 0.68609031],\n",
       "       [0.84853923, 0.04476457, 0.3494197 , 0.14859526],\n",
       "       [0.3907762 , 0.51925247, 0.40387419, 0.46743337],\n",
       "       [0.82952177, 0.15120962, 0.80575269, 0.05956335]])"
      ]
     },
     "execution_count": 471,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.82952177, 0.15120962, 0.80575269, 0.05956335])"
      ]
     },
     "execution_count": 472,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(a[:,2:3])\n",
    "a[3,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10025"
      ]
     },
     "execution_count": 473,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(hidden_layer_size * (input_layer_size + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
